# Hugging Face RAG Chat API ğŸš€

A simple **LLM-powered Retrieval-Augmented Generation (RAG) API** built **from scratch** using **Hugging Face open-source models**.  
You can upload documents, index them locally, and chat with an LLM that answers questions using your data.

This project runs **fully locally** (no OpenAI, no paid APIs).

---

## âœ¨ Features

- ğŸ“„ Upload `.txt` or `.md` documents
- ğŸ” Semantic search using embeddings + FAISS
- ğŸ¤– Question answering with Hugging Face LLMs
- ğŸ“š Source-aware answers (shows which document was used)
- âš¡ FastAPI backend with Swagger UI
- ğŸ§  Fully local inference (CPU friendly by default)

---

## ğŸ§  Architecture (High Level)

hf-rag-api/
â”‚
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ main.py # FastAPI app
â”‚ â”œâ”€â”€ rag.py # RAG logic (FAISS + LLM)
â”‚ â”œâ”€â”€ ingest.py # Document chunking
â”‚ â””â”€â”€ config.py # Central config
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Uploaded documents
â”‚ â””â”€â”€ index/ # FAISS index + metadata
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Create virtual environment

```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
```

## Install dependencies
```bash
pip install -r requirements.txt
```

## Run the Application
```bash
uvicorn app.main:app --reload
```

##API will be available at:

http://127.0.0.1:8000


###Swagger UI:
http://127.0.0.1:8000/docs

## Upload a Document

Use /upload endpoint in Swagger UI or via curl:
```bash
curl -X POST "http://127.0.0.1:8000/upload" \
  -F "file=@example.txt"

###Supported formats:
-.txt
-.md


## Upload a Document

Endpoint: /chat

Example request:


