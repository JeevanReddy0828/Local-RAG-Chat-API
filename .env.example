# ═══════════════════════════════════════════════════════════════════════════════
# Local RAG Chat API - Environment Configuration
# ═══════════════════════════════════════════════════════════════════════════════
# Copy to .env and customize as needed

# ─────────────────────────────────────────────────────────────────────────────
# Storage Paths
# ─────────────────────────────────────────────────────────────────────────────
DATA_DIR=data
RAW_DIR=data/raw
INDEX_DIR=data/index

# ─────────────────────────────────────────────────────────────────────────────
# Embedding Model
# ─────────────────────────────────────────────────────────────────────────────
# Options: intfloat/e5-small-v2, intfloat/e5-base-v2, intfloat/e5-large-v2
EMBED_MODEL=intfloat/e5-small-v2

# ─────────────────────────────────────────────────────────────────────────────
# Retrieval Settings
# ─────────────────────────────────────────────────────────────────────────────
TOP_K=4

# ─────────────────────────────────────────────────────────────────────────────
# Chunking Settings
# ─────────────────────────────────────────────────────────────────────────────
CHUNK_MAX_CHARS=1400
CHUNK_OVERLAP_CHARS=250

# ─────────────────────────────────────────────────────────────────────────────
# Ollama LLM Configuration
# ─────────────────────────────────────────────────────────────────────────────
OLLAMA_ENABLED=true
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral

# ─────────────────────────────────────────────────────────────────────────────
# Generation Settings
# ─────────────────────────────────────────────────────────────────────────────
MAX_NEW_TOKENS=512
TEMPERATURE=0.2

# ─────────────────────────────────────────────────────────────────────────────
# Session Settings
# ─────────────────────────────────────────────────────────────────────────────
MAX_HISTORY_TURNS=8
